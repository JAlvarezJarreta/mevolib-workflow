// See the NOTICE file distributed with this work for additional information
// regarding copyright ownership.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

nextflowVersion = '!>=22.11'

plugins {
    id 'nf-validation@1.1.3'
}

params {
    query = ""
    species = ""
    seq_type = ""
    refseq = false
    max_seqs = ""

    cluster_tool = ""

    align_tool = ""
    align_args = "default"
    align_out_format = "fasta"

    inference_tool = ""
    inference_args = "default"
    inference_out_format = "newick"
    inference_bootstraps = 200

    help = false
    input_file = ""
    input_format = ""
    output_dir = "${launchDir}/output"
    validate_params = true

}

trace {
    fields = 'task_id,name,process,hash,status,exit,attempt,submit,time,realtime,cpus,%cpu,memory,%mem'
}

process {

    maxRetries    = 2
    errorStrategy = { task.attempt < (process.maxRetries+1) ? 'retry' : 'ignore' }
    
    fetch_selected = !params.input_file && (params.query || params.species) ? 1 : 0
    cluster_selected = params.cluster_tool ? 1 : 0
    align_selected = params.align_tool ? 1 : 0
    inference_selected = params.inference_tool ? 1 : 0
    ref_seq_selected = params.refseq ? 1 : 0 
        
       time = {
            time_values = params.elapsed_time_json.values
            time_indep_term = params.elapsed_time_json.intercept
            
            total_time_prediction = time_values[0]*2000 + time_values[1]*process.fetch_selected +
            time_values[2]*process.cluster_selected + time_values[3]*process.align_selected + 
            time_values[4]*process.inference_selected + time_values[5]*process.ref_seq_selected +
            time_indep_term
            
            factor = ( ( (task.attempt-1) * 0.5 ) + 1)
           
            return total_time_prediction>0 ? factor*total_time_prediction/3*1.sec : 30.sec
    }
    
       withName: 'FETCH_SEQS' {
       
           time = {
            3.h
        }
       
    }
    
       withName: 'GET_GENES' {
       
         cpus = {
            file_size = file_path.size()
            process.predicted_num_seqs= file_size/4400
            
            cpu_values = (params.cpu_json.values.cluster_mean_cpu_usage-null)[0];
            cpu_indep_term = params.cpu_json.intercepts[1]
            
            predicted_cpus = Math.round((cpu_values[0]*process.predicted_num_seqs + 
            cpu_values[1]*process.fetch_selected + cpu_values[2]*process.cluster_selected + 
            cpu_values[3]*process.align_selected + cpu_values[4]*process.inference_selected + 
            cpu_indep_term)/100)

            return Math.max(1,predicted_cpus)
        }
        
         memory = {
            memory_values = (params.memory_json.values.cluster_mean_memory_usage-null)[0];
            memory_indep_term = params.memory_json.intercepts[1]
            
            predicted_memory = memory_values[0]*process.predicted_num_seqs + 
            memory_values[1]*process.fetch_selected + memory_values[2]*process.cluster_selected + 
            memory_values[3]*process.align_selected + memory_values[4]*process.inference_selected + 
            memory_indep_term
            
            factor = Math.pow(2, task.attempt - 1)

            return factor*predicted_memory*1.MB
        }
    }
    
       withName: 'GET_ALIGN' {
         cpus = {
            cpu_values = (params.cpu_json.values.align_max_cpu_usage-null)[0];
            cpu_indep_term = params.cpu_json.intercepts[4]
            
            predicted_cpus = Math.round((cpu_values[0]*process.predicted_num_seqs +
            cpu_values[1]*process.fetch_selected + cpu_values[2]*process.cluster_selected +
            cpu_values[3]*process.align_selected + cpu_values[4]*process.inference_selected +
            cpu_indep_term)/100)
       
            return Math.max(1,predicted_cpus)
        }
        
         memory = {
            memory_values = (params.memory_json.values.align_max_memory_usage-null)[0];
            memory_indep_term = params.memory_json.intercepts[4]
            
            predicted_memory = memory_values[0]*process.predicted_num_seqs +
            memory_values[1]*process.fetch_selected + memory_values[2]*process.cluster_selected + 
            memory_values[3]*process.align_selected + memory_values[4]*process.inference_selected +
            memory_indep_term
            
            factor = Math.pow(2, task.attempt - 1)

            return factor*predicted_memory*1.MB
        }
    }
    
       withName: 'GET_INFERENCE' {
         cpus = {
            cpu_values = (params.cpu_json.values.inference_max_cpu_usage-null)[0];
            cpu_indep_term = params.cpu_json.intercepts[5]
            
            predicted_cpus = Math.round((cpu_values[0]*process.predicted_num_seqs + 
            cpu_values[1]*process.fetch_selected + cpu_values[2]*process.cluster_selected +
            cpu_values[3]*process.align_selected + cpu_values[4]*process.inference_selected + 
            cpu_indep_term)/100)
       
            return Math.max(1,predicted_cpus)
        }
        
         memory = {
            memory_values = (params.memory_json.values.inference_max_memory_usage-null)[0];
            memory_indep_term = params.memory_json.intercepts[5]
            
            predicted_memory = memory_values[0]*process.predicted_num_seqs + 
            memory_values[1]*process.fetch_selected + memory_values[2]*process.cluster_selected + 
            memory_values[3]*process.align_selected + memory_values[4]*process.inference_selected +
            memory_indep_term
            
            factor = Math.pow(2, task.attempt - 1)

            return factor*predicted_memory*1.MB
        }
    }
       

}